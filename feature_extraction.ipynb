{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pyspark.ml.classification import LogisticRegression ,RandomForestClassifier ,LinearSVC\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator \n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from apyori import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark=SparkSession.builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"WordCount\")\\\n",
    "    .getOrCreate()\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=pd.read_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val, test = train_test_split(new_df, test_size=0.1, random_state=42)\n",
    "train, val = train_test_split(train_val, test_size=0.22, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train.csv\")\n",
    "val.to_csv(\"val.csv\")\n",
    "test.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df= train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=new_df.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    139405\n",
      "1     95360\n",
      "Name: state, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# convert labels to int so we can apply classification on them\n",
    "new_df.loc[new_df['state'] == 'failed','state'] = 0\n",
    "new_df.loc[new_df['state'] == 'successful','state'] = 1\n",
    "\n",
    "new_df['state'] = new_df['state'].astype('int64')\n",
    "\n",
    "val.loc[val['state'] == 'failed','state'] = 0\n",
    "val.loc[val['state'] == 'successful','state'] = 1\n",
    "\n",
    "val['state'] = val['state'].astype('int64')\n",
    "\n",
    "\n",
    "test.loc[test['state'] == 'failed','state'] = 0\n",
    "test.loc[test['state'] == 'successful','state'] = 1\n",
    "\n",
    "test['state'] = test['state'].astype('int64')\n",
    "\n",
    "print(new_df['state'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove useless features\n",
    "data_model = new_df.drop(['ID','name','goal','category','deadline','launched'],axis=1)\n",
    "# remove useless features\n",
    "val = val.drop(['ID','name','goal','category','deadline','launched'],axis=1)\n",
    "# remove useless features\n",
    "test = test.drop(['ID','name','goal','category','deadline','launched'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['main_category' 'currency' 'pledged' 'state' 'backers' 'country'\n",
      " 'usd pledged']\n"
     ]
    }
   ],
   "source": [
    "print(data_model.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data_model)\n",
    "val = spark.createDataFrame(val)\n",
    "test = spark.createDataFrame(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- main_category: string (nullable = true)\n",
      " |-- currency: string (nullable = true)\n",
      " |-- pledged: double (nullable = true)\n",
      " |-- state: long (nullable = true)\n",
      " |-- backers: double (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- usd pledged: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+-------+-----+-------+-------+-----------+\n",
      "|main_category|currency|pledged|state|backers|country|usd pledged|\n",
      "+-------------+--------+-------+-----+-------+-------+-----------+\n",
      "|        Games|     GBP| 7529.0|    1|  206.0|     GB|   10798.12|\n",
      "|          Art|     USD|  331.0|    0|    6.0|     US|      331.0|\n",
      "+-------------+--------+-------+-----+-------+-------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_features(feature_input,feature_output,df):\n",
    "    qualification_indexer = StringIndexer(inputCol=feature_input, outputCol=feature_output)#Fits a model to the input dataset with optional parameters.\n",
    "    df = qualification_indexer.fit(df).transform(df)\n",
    "    # df.show()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(index,vec,df):\n",
    "    onehotencoder_qualification_vector = OneHotEncoder(inputCol=index, outputCol=vec)\n",
    "    df = onehotencoder_qualification_vector.fit(df).transform(df)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=encoding_features(\"main_category\",\"main_category_index\",df)\n",
    "df =one_hot_encoder(\"main_category_index\",\"main_category_vec\",df)\n",
    "val=encoding_features(\"main_category\",\"main_category_index\",val)\n",
    "val =one_hot_encoder(\"main_category_index\",\"main_category_vec\",val)\n",
    "test=encoding_features(\"main_category\",\"main_category_index\",test)\n",
    "test =one_hot_encoder(\"main_category_index\",\"main_category_vec\",test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=encoding_features(\"currency\",\"currency_index\",df)\n",
    "df =one_hot_encoder(\"currency_index\",\"currency_vec\",df)\n",
    "val=encoding_features(\"currency\",\"currency_index\",val)\n",
    "val =one_hot_encoder(\"currency_index\",\"currency_vec\",val)\n",
    "test=encoding_features(\"currency\",\"currency_index\",test)\n",
    "test =one_hot_encoder(\"currency_index\",\"currency_vec\",test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# ! Not required\n",
    "#df=encoding_features(\"pledged\",\"pledged_index\",df)\n",
    "#df =one_hot_encoder(\"pledged_index\",\"pledged_vec\",df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=encoding_features(\"country\",\"country_index\",df)\n",
    "df=one_hot_encoder(\"country_index\",\"country_vec\",df)\n",
    "val=encoding_features(\"country\",\"country_index\",val)\n",
    "val=one_hot_encoder(\"country_index\",\"country_vec\",val)\n",
    "test=encoding_features(\"country\",\"country_index\",test)\n",
    "test=one_hot_encoder(\"country_index\",\"country_vec\",test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['main_category',\n",
       " 'currency',\n",
       " 'pledged',\n",
       " 'state',\n",
       " 'backers',\n",
       " 'country',\n",
       " 'usd pledged',\n",
       " 'main_category_index',\n",
       " 'main_category_vec',\n",
       " 'currency_index',\n",
       " 'currency_vec',\n",
       " 'country_index',\n",
       " 'country_vec']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols = ['main_category_vec', 'currency_vec' ,'pledged', 'backers' ,'country_vec',\n",
    " 'usd pledged'], outputCol='features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = assembler.transform(df)\n",
    "val = assembler.transform(val)\n",
    "test = assembler.transform(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol=\"state\",maxIter=10)\n",
    "lrn = lr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7805707424837259\n"
     ]
    }
   ],
   "source": [
    "predictions = lrn.transform(val)\n",
    "\n",
    "eval = BinaryClassificationEvaluator(rawPredictionCol = \"prediction\", labelCol = \"state\")\n",
    "auc = eval.evaluate(predictions)\n",
    "print(auc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(maxIter=30, regParam=0.0001,labelCol=\"state\")\n",
    "lsvcModel = lsvc.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7360181163613487\n"
     ]
    }
   ],
   "source": [
    "predictions = lsvcModel.transform(val)\n",
    "eval = BinaryClassificationEvaluator(rawPredictionCol = \"prediction\", labelCol = \"state\")\n",
    "auc = eval.evaluate(predictions)\n",
    "print(auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0eefc6a63c6d719296cee5685f23fefb92aa63e2e9fdaf52ddbdc4ce266c7bb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
